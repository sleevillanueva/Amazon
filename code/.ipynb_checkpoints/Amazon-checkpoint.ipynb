{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Case Study, I want to demonstrate how we can use Pipelines and LDA. We are also going to have Decision Trees as our base classifier and we are going to explore some ensemble methods such as Bagging Classifier, Random Forest Classifier, AdaBoost Classifier and Gradient Boosting Classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I always start with importing pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import the CSV using pandas read_csv. The csv file is in the same folder so there's no need to specify the path\n",
    "amazon = pd.read_csv(\"../assets/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39353</td>\n",
       "      <td>85475</td>\n",
       "      <td>117961</td>\n",
       "      <td>118300</td>\n",
       "      <td>123472</td>\n",
       "      <td>117905</td>\n",
       "      <td>117906</td>\n",
       "      <td>290919</td>\n",
       "      <td>117908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17183</td>\n",
       "      <td>1540</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>123125</td>\n",
       "      <td>118536</td>\n",
       "      <td>118536</td>\n",
       "      <td>308574</td>\n",
       "      <td>118539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>36724</td>\n",
       "      <td>14457</td>\n",
       "      <td>118219</td>\n",
       "      <td>118220</td>\n",
       "      <td>117884</td>\n",
       "      <td>117879</td>\n",
       "      <td>267952</td>\n",
       "      <td>19721</td>\n",
       "      <td>117880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36135</td>\n",
       "      <td>5396</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>119993</td>\n",
       "      <td>118321</td>\n",
       "      <td>240983</td>\n",
       "      <td>290919</td>\n",
       "      <td>118322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>42680</td>\n",
       "      <td>5905</td>\n",
       "      <td>117929</td>\n",
       "      <td>117930</td>\n",
       "      <td>119569</td>\n",
       "      <td>119323</td>\n",
       "      <td>123932</td>\n",
       "      <td>19793</td>\n",
       "      <td>119325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTION  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
       "0       1     39353   85475         117961         118300         123472   \n",
       "1       1     17183    1540         117961         118343         123125   \n",
       "2       1     36724   14457         118219         118220         117884   \n",
       "3       1     36135    5396         117961         118343         119993   \n",
       "4       1     42680    5905         117929         117930         119569   \n",
       "\n",
       "   ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
       "0      117905            117906       290919     117908  \n",
       "1      118536            118536       308574     118539  \n",
       "2      117879            267952        19721     117880  \n",
       "3      118321            240983       290919     118322  \n",
       "4      119323            123932        19793     119325  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACTION              0\n",
       "RESOURCE            0\n",
       "MGR_ID              0\n",
       "ROLE_ROLLUP_1       0\n",
       "ROLE_ROLLUP_2       0\n",
       "ROLE_DEPTNAME       0\n",
       "ROLE_TITLE          0\n",
       "ROLE_FAMILY_DESC    0\n",
       "ROLE_FAMILY         0\n",
       "ROLE_CODE           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if there are null values that we have to deal with\n",
    "amazon.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no values that need to be taken care of. We know that the first column is our target column. 1 means the resource was approved and 0 if it was not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RESOURCE</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011088</td>\n",
       "      <td>-0.005016</td>\n",
       "      <td>0.013438</td>\n",
       "      <td>0.030004</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.021029</td>\n",
       "      <td>0.031060</td>\n",
       "      <td>0.007733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MGR_ID</th>\n",
       "      <td>0.011088</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007132</td>\n",
       "      <td>-0.000364</td>\n",
       "      <td>-0.009551</td>\n",
       "      <td>0.017864</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>-0.118254</td>\n",
       "      <td>-0.004067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <td>-0.005016</td>\n",
       "      <td>-0.007132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033358</td>\n",
       "      <td>-0.009548</td>\n",
       "      <td>0.010207</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>-0.024927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <td>0.013438</td>\n",
       "      <td>-0.000364</td>\n",
       "      <td>0.033358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006056</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>0.018873</td>\n",
       "      <td>0.069558</td>\n",
       "      <td>0.015117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <td>0.030004</td>\n",
       "      <td>-0.009551</td>\n",
       "      <td>-0.009548</td>\n",
       "      <td>-0.006056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006932</td>\n",
       "      <td>-0.002877</td>\n",
       "      <td>0.031669</td>\n",
       "      <td>0.010319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.017864</td>\n",
       "      <td>0.010207</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>-0.006932</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170692</td>\n",
       "      <td>-0.012450</td>\n",
       "      <td>0.155920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <td>0.021029</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>0.018873</td>\n",
       "      <td>-0.002877</td>\n",
       "      <td>0.170692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.180596</td>\n",
       "      <td>0.092980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <td>0.031060</td>\n",
       "      <td>-0.118254</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.069558</td>\n",
       "      <td>0.031669</td>\n",
       "      <td>-0.012450</td>\n",
       "      <td>-0.180596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROLE_CODE</th>\n",
       "      <td>0.007733</td>\n",
       "      <td>-0.004067</td>\n",
       "      <td>-0.024927</td>\n",
       "      <td>0.015117</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>0.155920</td>\n",
       "      <td>0.092980</td>\n",
       "      <td>-0.148625</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RESOURCE    MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  \\\n",
       "RESOURCE          1.000000  0.011088      -0.005016       0.013438   \n",
       "MGR_ID            0.011088  1.000000      -0.007132      -0.000364   \n",
       "ROLE_ROLLUP_1    -0.005016 -0.007132       1.000000       0.033358   \n",
       "ROLE_ROLLUP_2     0.013438 -0.000364       0.033358       1.000000   \n",
       "ROLE_DEPTNAME     0.030004 -0.009551      -0.009548      -0.006056   \n",
       "ROLE_TITLE        0.002936  0.017864       0.010207       0.008305   \n",
       "ROLE_FAMILY_DESC  0.021029 -0.018488      -0.007546       0.018873   \n",
       "ROLE_FAMILY       0.031060 -0.118254       0.029468       0.069558   \n",
       "ROLE_CODE         0.007733 -0.004067      -0.024927       0.015117   \n",
       "\n",
       "                  ROLE_DEPTNAME  ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  \\\n",
       "RESOURCE               0.030004    0.002936          0.021029     0.031060   \n",
       "MGR_ID                -0.009551    0.017864         -0.018488    -0.118254   \n",
       "ROLE_ROLLUP_1         -0.009548    0.010207         -0.007546     0.029468   \n",
       "ROLE_ROLLUP_2         -0.006056    0.008305          0.018873     0.069558   \n",
       "ROLE_DEPTNAME          1.000000   -0.006932         -0.002877     0.031669   \n",
       "ROLE_TITLE            -0.006932    1.000000          0.170692    -0.012450   \n",
       "ROLE_FAMILY_DESC      -0.002877    0.170692          1.000000    -0.180596   \n",
       "ROLE_FAMILY            0.031669   -0.012450         -0.180596     1.000000   \n",
       "ROLE_CODE              0.010319    0.155920          0.092980    -0.148625   \n",
       "\n",
       "                  ROLE_CODE  \n",
       "RESOURCE           0.007733  \n",
       "MGR_ID            -0.004067  \n",
       "ROLE_ROLLUP_1     -0.024927  \n",
       "ROLE_ROLLUP_2      0.015117  \n",
       "ROLE_DEPTNAME      0.010319  \n",
       "ROLE_TITLE         0.155920  \n",
       "ROLE_FAMILY_DESC   0.092980  \n",
       "ROLE_FAMILY       -0.148625  \n",
       "ROLE_CODE          1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's look at the correlation of the features\n",
    "#This will give us a table of the correlation\n",
    "amazon.iloc[:,1:].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11ce7e410>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAFaCAYAAACKb4N+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGf8/LthlDA0Hm9AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ceae350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#I like looking at visuals though, so I'm going to make a heatmap using seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sns.heatmap(amazon.iloc[:,1:].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there's no correlation between our features which is good. What does this mean? When you have strong correlations between two features, it means that those features are saying the same thing and if you put both in your model, you're sort of putting twice as much weight for that feature.\n",
    "\n",
    "Pipelines let us process data iteratively. You can think about it like grouping a set of actions where the first output would be the second's input and so on. An example of usage for this, which we will be doing in this case study, is putting a transformation step and our resulting estimator in a single interface. The first steps in your pipeline should be tranformative steps, and the last one is normally predictive, but you can always have all transformative steps. \n",
    "\n",
    "Fisher's Linear Discriminant Analysis (LDA) is a method where our data is projected to some space but also considers class in that space to have a clearly defined class. In LDA, feature sets are mutually independent and there is one covariance matrix for the multi-class target.\n",
    "\n",
    "Decision Trees Classification is a supervised learning method where we create a model that predicts the value of a target variable, in our case it's the \"ACTION\" column which is binary, by learning simple decision rules from the features set.\n",
    "\n",
    "We are also going to take a look at an ensemble meta-estimator called Bagging Classifier. It randomly takes subsets the original dataset and fits these to the classifier of our choosing. It then aggregates the subsets' individual predictions (either by voting or by averaging) to form a final prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#let's do our imports for pipelines, LDA, StandardScaler, Decision Trees.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I'm setting my X to all the features because we're going to apply LDA and Decision Tree using a pipeline\n",
    "#The target is our \"ACTION\" column\n",
    "X = amazon[amazon.columns[1:].tolist()]\n",
    "y = amazon[\"ACTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's initialize a Decision Tree Classifier.\n",
    "#Normally, we can just initialize the classifier inside our pipeline, but because we will do some ensembling methods,\n",
    "#we would need to initialize it again later.\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = make_pipeline(StandardScaler(),LinearDiscriminantAnalysis(),BaggingClassifier(dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not going to do a train test split for now. The reason behind this is because we have a test set where we would test our model on. So for now, I'm going to be using all of the data from train.csv and train our model from there. Our objective is to find the best features that would give us a high accuracy score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lineardiscriminantanalysis', LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)), ('baggingclassifier', BaggingClassifier(bas...estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import the test data and we will fit it to our model\n",
    "#We are also importing the sample submission which is basically a column of ids and actions\n",
    "test = pd.read_csv(\"../assets/test.csv\")\n",
    "sample = pd.read_csv(\"../assets/sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "RESOURCE            0\n",
       "MGR_ID              0\n",
       "ROLE_ROLLUP_1       0\n",
       "ROLE_ROLLUP_2       0\n",
       "ROLE_DEPTNAME       0\n",
       "ROLE_TITLE          0\n",
       "ROLE_FAMILY_DESC    0\n",
       "ROLE_FAMILY         0\n",
       "ROLE_CODE           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test[test.columns[1:].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "sample['Action'] = predictions\n",
    "sample.to_csv('../results/bagging_dt_LDA.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we didn't get a great score when we used this model for our test data. So we're gonna attempt to see if some optimization will help. Let's try to do a gridsearch on our pipeline. We can look at the parameters to tweak by doing a get_params() on our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baggingclassifier__oob_score',\n",
       " 'baggingclassifier__base_estimator__min_weight_fraction_leaf',\n",
       " 'lineardiscriminantanalysis__store_covariance',\n",
       " 'lineardiscriminantanalysis',\n",
       " 'baggingclassifier__random_state',\n",
       " 'baggingclassifier__base_estimator__presort',\n",
       " 'baggingclassifier__n_estimators',\n",
       " 'lineardiscriminantanalysis__n_components',\n",
       " 'lineardiscriminantanalysis__shrinkage',\n",
       " 'baggingclassifier__base_estimator',\n",
       " 'standardscaler__copy',\n",
       " 'baggingclassifier__verbose',\n",
       " 'baggingclassifier__base_estimator__random_state',\n",
       " 'baggingclassifier__max_features',\n",
       " 'baggingclassifier__base_estimator__min_samples_leaf',\n",
       " 'baggingclassifier__bootstrap_features',\n",
       " 'baggingclassifier__base_estimator__max_depth',\n",
       " 'baggingclassifier__base_estimator__max_leaf_nodes',\n",
       " 'baggingclassifier__bootstrap',\n",
       " 'standardscaler',\n",
       " 'baggingclassifier__max_samples',\n",
       " 'standardscaler__with_mean',\n",
       " 'baggingclassifier__base_estimator__class_weight',\n",
       " 'baggingclassifier__base_estimator__min_samples_split',\n",
       " 'baggingclassifier',\n",
       " 'lineardiscriminantanalysis__priors',\n",
       " 'baggingclassifier__n_jobs',\n",
       " 'standardscaler__with_std',\n",
       " 'baggingclassifier__warm_start',\n",
       " 'baggingclassifier__base_estimator__criterion',\n",
       " 'lineardiscriminantanalysis__solver',\n",
       " 'lineardiscriminantanalysis__tol',\n",
       " 'steps',\n",
       " 'baggingclassifier__base_estimator__splitter',\n",
       " 'baggingclassifier__base_estimator__max_features']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'baggingclassifier__n_estimators':[50,100,250,500],\n",
    "    'lineardiscriminantanalysis__n_components':[2,3,4,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lineardiscriminantanalysis', LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)), ('baggingclassifier', BaggingClassifier(bas...estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'lineardiscriminantanalysis__n_components': [2, 3, 4, 5], 'baggingclassifier__n_estimators': [50, 100, 250, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(model, params, cv=5, verbose=1, n_jobs=-1,scoring=\"roc_auc\")\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = gs.predict(X_test)\n",
    "sample['Action'] = predictions\n",
    "sample.to_csv('../results/bagging_dt_LDA_gs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This still does not produce good results. Let's take a look at Random Forest Classifier, AdaBoost Classifier and Gradient Boosting Classifier.\n",
    "\n",
    "Random Forest Classifier takes a number of various sub-samples of the original dataset and fits these to decision tree classifiers. It uses averaging to improve the predictive accuracy and to control over-fitting. \n",
    "\n",
    "AdaBoos Classifier\n",
    "\n",
    "Gradient Boosting Classifier\n",
    "\n",
    "For this section of our code, I'm going to define a function that prints out the scores from cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(y, n_folds=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(model, name):\n",
    "    s = cross_val_score(model, X, y, cv=cv,scoring=\"roc_auc\")\n",
    "    print \"{} Score:\\t{:0.3} ± {:0.3}\".format(name, s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import our ensembles\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize our random forest. Since we did not specify it in our parameters, the number of trees in our forest would\n",
    "#be 10 as a default\n",
    "rf = RandomForestClassifier(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's fit our X and y\n",
    "rf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESOURCE 0.212209397587\n",
      "MGR_ID 0.192951826097\n",
      "ROLE_ROLLUP_1 0.0555242337099\n",
      "ROLE_ROLLUP_2 0.0982312953737\n",
      "ROLE_DEPTNAME 0.134580567311\n",
      "ROLE_TITLE 0.0617754786201\n",
      "ROLE_FAMILY_DESC 0.119406141722\n",
      "ROLE_FAMILY 0.0591502235823\n",
      "ROLE_CODE 0.0661708359961\n"
     ]
    }
   ],
   "source": [
    "#One method the ensembles we are going to look at have that we can make use of is the feature_importances_.\n",
    "#As the name suggests, this will show us how predictive our features are. It will return an array of percentages of \n",
    "#our features. To make it so that it makes more sense to us, I'm going to have the feature names beside the %.\n",
    "#Let's take a look at them for our Random Forest Classifier.\n",
    "\n",
    "for a,b in zip(test.columns[1:].tolist(), rf.feature_importances_):\n",
    "    print a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Score:\t0.798 ± 0.013\n"
     ]
    }
   ],
   "source": [
    "#Let's look at the cross val score of our Random Forest\n",
    "score(rf, \"Random Forest Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESOURCE 0.16\n",
      "MGR_ID 0.1\n",
      "ROLE_ROLLUP_1 0.12\n",
      "ROLE_ROLLUP_2 0.18\n",
      "ROLE_DEPTNAME 0.08\n",
      "ROLE_TITLE 0.02\n",
      "ROLE_FAMILY_DESC 0.16\n",
      "ROLE_FAMILY 0.1\n",
      "ROLE_CODE 0.08\n"
     ]
    }
   ],
   "source": [
    "#Initialize adaboost, fit and let's check the feature importances like we did for Random Forest Classifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X,y)\n",
    "\n",
    "for a,b in zip(test.columns[1:].tolist(), ada.feature_importances_):\n",
    "    print a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Boosting Classifier Score:\t0.694 ± 0.013\n"
     ]
    }
   ],
   "source": [
    "#Let's look at the cross val score of our AdaBoost\n",
    "score(ada, \"Adaptive Boosting Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESOURCE 0.163952455259\n",
      "MGR_ID 0.191697643389\n",
      "ROLE_ROLLUP_1 0.0741931166637\n",
      "ROLE_ROLLUP_2 0.132903153495\n",
      "ROLE_DEPTNAME 0.0950871974162\n",
      "ROLE_TITLE 0.0597902282949\n",
      "ROLE_FAMILY_DESC 0.157679303374\n",
      "ROLE_FAMILY 0.0796379563204\n",
      "ROLE_CODE 0.0450589457877\n"
     ]
    }
   ],
   "source": [
    "#Lastly, let's do this for the gradient boosting classifier\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X,y)\n",
    "\n",
    "for a,b in zip(test.columns[1:].tolist(), gb.feature_importances_):\n",
    "    print a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Score:\t0.754 ± 0.008\n"
     ]
    }
   ],
   "source": [
    "score(gb, \"Gradient Boosting Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#It seems like our Random Forest has the best score, so before using the feature importances, let's run the test data\n",
    "#on our model so that we can see what Random Forest outputs and see if we can play around with the features.\n",
    "predictions = rf.predict(X_test)\n",
    "sample['Action'] = predictions\n",
    "sample.to_csv('../results/rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our score jumped up more than 10%. Cool. Let's take a look at optimizing our random forest and see if that helps with our score. After which, let's try pulling out some features and do a simple logistic regression on it and see if that gives us a better score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.StratifiedKFold(labels=[1 1 ..., 1 1], n_folds=5, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [3, 5, 10, 50], 'min_samples_split': [2, 5], 'criterion': ['gini', 'entropy'], 'max_depth': [3, 5, 10, 20], 'class_weight': [None, 'balanced']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators':[3, 5, 10, 50],\n",
    "          'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': [3, 5, 10, 20],\n",
    "          'min_samples_split': [2,5],\n",
    "          'class_weight':[None, 'balanced']}\n",
    "\n",
    "\n",
    "gsrf = GridSearchCV(rf,params, n_jobs=-1,cv=cv,scoring=\"roc_auc\")\n",
    "gsrf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = gsrf.predict(X_test)\n",
    "sample['Action'] = predictions\n",
    "sample.to_csv('../results/gs_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing an optimization problem in our case hurts us as we can see from the drop in score. This may be because we are over-fitting our model to our train data and this doesn't do well when we fit it to our test data. Let's try selecting features from the feature importances list that we had a while ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
